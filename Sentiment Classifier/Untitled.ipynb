{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeadba3-5e1d-499e-a56e-3dc7a1c85a71",
   "metadata": {},
   "source": [
    "<h1>Sentiment Classification Using LogisticRegression - IMDB Reviews</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "848eb50c-286c-4cdb-9c88-f9706db21607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e49417d-dbb9-48ec-a8f6-f8c5b69dfbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "dataSet=pd.read_csv(r\"D:\\Datasets\\IMDB Dataset.csv\")\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f63ad6-b3e5-4d6b-ac18-bc0598f30a3f",
   "metadata": {},
   "source": [
    "<h2> Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1895a03f-4921-4fa9-9a33-e5534727197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative']\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for any null  values\n",
    "print(pd.unique(dataSet['sentiment']))\n",
    "print(dataSet.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b7d38dd-2df4-4541-a68a-fd40d42793ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn The sentiment into numbers\n",
    "\n",
    "label_mapping={'positive':1,'negative':0}\n",
    "\n",
    "dataSet['sentiment'] = dataSet['sentiment'].map(label_mapping)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4cc3a10d-fd2e-4a75-a9c4-fc4ca62c31f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Create Positive and negative dicts\n",
    "global nlp\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "global pos_dict,neg_dict\n",
    "pos_dict,neg_dict={},{}\n",
    "#Pre train the pos and neg dicts\n",
    "\n",
    "with open(\"Positive.txt\" ,'r') as pos:\n",
    "    pos_list=pos.read().split()\n",
    "with open(\"Negative.txt\",'r') as neg:\n",
    "    neg_list=neg.read().split()\n",
    "\n",
    "for i in pos_list:\n",
    "    pos_dict[i]=0\n",
    "for i in neg_list:\n",
    "    neg_dict[i]=0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fdc56-3f43-44de-820e-6f6cb81cffc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ea485c9-06af-43af-b5ac-b3f4897e463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define Methods for cleaning , processing and extracting features from the data\n",
    "\n",
    "\n",
    "def remove_stops(arr):\n",
    "    \n",
    "    stop_words = nlp.Defaults.stop_words\n",
    "    doc=nlp(arr)\n",
    "    cleaned_tokens = [token.text for token in doc if token.text not in stop_words and not token.is_punct]\n",
    "    doc=nlp(\" \".join(cleaned_tokens))\n",
    "    cleaned_tokens=[token.lemma_ for  token in doc]\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "def apply_regex(arr):\n",
    "\n",
    "    pattern=r\"@\\S+|https?:\\/\\/\\S+|www\\.\\S+|<br\\s*/?>\"\n",
    "    cleaned_text=re.sub(pattern,'',arr)\n",
    "    return cleaned_text\n",
    "\n",
    "def extract_feature_vector(arr):\n",
    "    words=arr.split()\n",
    "    for word in words:\n",
    "        if word in pos_dict:\n",
    "            pos_dict[word] += 1\n",
    "        elif word in neg_dict:\n",
    "            neg_dict[word] += 1\n",
    "    \n",
    "    pos_sum = sum(pos_dict.values())\n",
    "    neg_sum = sum(neg_dict.values())\n",
    "    for i in pos_list:\n",
    "        pos_dict[i]=0\n",
    "    for i in neg_list:\n",
    "        neg_dict[i]=0\n",
    "    \n",
    "    return np.array([1, pos_sum, neg_sum])\n",
    "print(dataSet['review'][9])\n",
    "text=remove_stops(dataSet['review'][9])\n",
    "text=apply_regex(\" \".join(text))\n",
    "extract_feature_vector(text)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f376ee94-46d8-4b0a-94bf-c79e4acaad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "train_x,test_x,train_y,test_y=train_test_split(list(dataSet['review']),list(dataSet['sentiment']),random_state=3,train_size=5000,test_size=0.33)\n",
    "for i in range(len(train_x)):\n",
    "    text=remove_stops(train_x[i])\n",
    "    text=apply_regex(\" \".join(text))\n",
    "    train_x[i]=extract_feature_vector(text)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1694da85-560f-48a7-9f3f-7e33f26f37ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_1=torch.tensor(train_y).reshape(5000,1)\n",
    "test_y=torch.tensor(test_y)\n",
    "train_x=torch.tensor(train_x).squeeze().float()\n",
    "train_y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12111c1a-7fc9-4cda-b2b3-7471a80f746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,lr,epochs,feature_no):\n",
    "        super().__init__()\n",
    "        self.epoch=epochs\n",
    "        self.l1=nn.Linear(feature_no,1)\n",
    "        self.optimizer=torch.optim.SGD(self.parameters(),momentum=0.5,lr=lr)\n",
    "        self.loss=nn.BCELoss()\n",
    "        self.activation=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.activation(self.l1(x))\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred=self.forward(x)\n",
    "            loss=self.loss(y_pred,y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "41f33009-6876-42d2-9c40-ca4a7b9a465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model=LogisticRegression(0.01,1000,3)\n",
    "model.fit(train_x,train_y_1.float())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3195dbc9-78b3-4d76-a96f-7a20345108d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_x))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_x)):\n\u001b[1;32m----> 4\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[43mremove_stops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     text\u001b[38;5;241m=\u001b[39mapply_regex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text))\n\u001b[0;32m      6\u001b[0m     test_x[i]\u001b[38;5;241m=\u001b[39mextract_feature_vector(text)\n",
      "Cell \u001b[1;32mIn[143], line 7\u001b[0m, in \u001b[0;36mremove_stops\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_stops\u001b[39m(arr):\n\u001b[0;32m      6\u001b[0m     stop_words \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mDefaults\u001b[38;5;241m.\u001b[39mstop_words\n\u001b[1;32m----> 7\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     cleaned_tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_punct]\n\u001b[0;32m      9\u001b[0m     doc\u001b[38;5;241m=\u001b[39mnlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cleaned_tokens))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1018\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1037\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1039\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1131\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n\u001b[1;32m-> 1131\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE1041\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[1;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d2c25-aae4-4d40-a41f-626490707fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
